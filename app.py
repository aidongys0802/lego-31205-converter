import streamlit as st
import numpy as np
import cv2
from PIL import Image, ImageEnhance
import random
st.set_page_config(page_title="LEGO 31205 è‰ºæœ¯å¤§å¸ˆç‰ˆ", layout="wide")
# 1. ä¸¥æ ¼ 31205 é›¶ä»¶åº“åŠåº“å­˜
LEGO_INVENTORY = {
   "Black": [(0, 0, 0), 600], "Dark Stone Grey": [(99, 95, 97), 470],
   "Medium Stone Grey": [(150, 152, 152), 370], "White": [(255, 255, 255), 350],
   "Navy Blue": [(27, 42, 52), 310], "Blue": [(0, 85, 191), 280],
   "Medium Azure": [(0, 174, 216), 170], "Light Aqua": [(188, 225, 233), 140],
   "Tan": [(217, 187, 123), 140], "Flesh": [(255, 158, 146), 140],
   "Dark Orange": [(168, 84, 9), 110], "Reddish Brown": [(127, 51, 26), 100],
   "Red": [(215, 0, 0), 100], "Medium Lavender": [(156, 124, 204), 100],
   "Sand Blue": [(112, 129, 154), 100]
}
@st.cache_resource
def load_cascade():
   # åŠ è½½ OpenCV äººè„¸æ£€æµ‹å™¨
   return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
def get_best_color(target_rgb, current_inv, is_face_roi=False, dither_rate=0.0):
   """
   æ ¸å¿ƒé…è‰²é€»è¾‘ï¼š
   - target_rgb: ç›®æ ‡åƒç´ å€¼
   - is_face_roi: æ˜¯å¦ä¸ºäººè„¸åŒºåŸŸ
   - dither_rate: ç¨€ç–æŠ–åŠ¨é¢‘ç‡ï¼ˆç”¨äºè¡¨ç°çš®è‚¤è´¨æ„Ÿï¼‰
   """
   tr, tg, tb = [int(np.clip(c, 0, 255)) for c in target_rgb]
   # å®šä¹‰äººè„¸æ ¸å¿ƒè‰²æ¿
   skin_base = ["Flesh", "White", "Tan", "Dark Orange", "Reddish Brown", "Black"]
   # å®šä¹‰å¦†é€ /è‰ºæœ¯ç‚¹ç¼€è‰²æ¿
   makeup_colors = ["Red", "Medium Lavender", "Medium Azure", "Blue", "Light Aqua", "Navy Blue"]
   # çš®è‚¤éšæœºé«˜å…‰å¤„ç† (Flesh æ·· White)
   if is_face_roi and dither_rate > 0 and random.random() < dither_rate:
       tr, tg, tb = [min(255, c + 35) for c in [tr, tg, tb]]
   # é€šè¿‡é¥±å’Œåº¦è¯†åˆ«å¦†é€ ï¼ˆå¦‚çº¢å”‡ã€å½©å¦†ï¼‰
   max_c, min_c = max(tr, tg, tb), min(tr, tg, tb)
   sat = (max_c - min_c) / (max_c + 0.1)
   best_dist = float('inf')
   best_name = "Black"
   for name, (rgb, count) in current_inv.items():
       if count <= 0: continue
       if is_face_roi:
           # é€»è¾‘ï¼šä½é¥±å’Œåº¦åŒºåŸŸå¼ºåˆ¶ä½¿ç”¨è‚¤è‰²ï¼Œé«˜é¥±å’Œåº¦åŒºåŸŸå…è®¸ä½¿ç”¨å½©è‰²ç§¯æœ¨è¡¨ç°å¦†é€ 
           if sat < 0.25 and name not in skin_base: continue
           if sat >= 0.25 and name not in (skin_base + makeup_colors): continue
       # åŠ æƒæ„ŸçŸ¥è‰²å½©è·ç¦» (äººçœ¼å¯¹ç»¿è‰²æ›´æ•æ„Ÿ)
       dr, dg, db = rgb[0] - tr, rgb[1] - tg, rgb[2] - tb
       dist = 2*dr**2 + 4*dg**2 + 3*db**2
       if dist < best_dist:
           best_dist, best_name = dist, name
   current_inv[best_name][1] -= 1
   return current_inv[best_name][0], best_name
# --- ä¾§è¾¹æ æ‰€æœ‰æ§åˆ¶æ»‘å— ---
st.sidebar.header("ğŸ›ï¸ å›¾åƒå¢å¼ºæ§åˆ¶")
brightness = st.sidebar.slider("1. æ•´ä½“äº®åº¦ (æäº®çš®è‚¤)", 0.5, 2.0, 1.1)
contrast = st.sidebar.slider("2. äº”å®˜é”åº¦ (å¯¹æ¯”åº¦)", 0.5, 2.5, 1.4)
skin_dither = st.sidebar.slider("3. çš®è‚¤è´¨æ„Ÿç‚¹ (ç¨€ç–æŠ–åŠ¨)", 0.0, 0.4, 0.05)
st.sidebar.header("ğŸ“ æ„å›¾è®¾ç½®")
zoom = st.sidebar.slider("å¯¹ç„¦èŒƒå›´ (Zoom)", 1.0, 3.0, 1.8)
uploaded_file = st.file_uploader("ä¸Šä¼ ç…§ç‰‡å¼€å§‹è½¬æ¢", type=["jpg", "png", "jpeg"])
if uploaded_file:
   # A. å›¾åƒåŠ è½½ä¸åŸºç¡€å¢å¼º
   img_pil = Image.open(uploaded_file).convert("RGB")
   img_pil = ImageEnhance.Brightness(img_pil).enhance(brightness)
   img_pil = ImageEnhance.Contrast(img_pil).enhance(contrast)
   # B. äººè„¸å®šä½ä¸æ™ºèƒ½è£å‰ª
   cv_img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
   faces = load_cascade().detectMultiScale(cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY), 1.1, 4)
   w, h = img_pil.size
   grid_res = 48 # å›ºå®šä¸º 31205 æ ‡å‡†å°ºå¯¸
   if len(faces) > 0:
       # é€‰æ‹©ç”»é¢ä¸­æœ€å¤§çš„äººè„¸è¿›è¡Œå¯¹ç„¦
       fx, fy, fw, fh = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)[0]
       cx, cy = fx + fw//2, fy + fh//2
       crop_dim = int(min(w, h) / zoom)
       left, top = max(0, cx - crop_dim//2), max(0, cy - crop_dim//2)
       img_cropped = img_pil.crop((left, top, min(w, left+crop_dim), min(h, top+crop_dim)))
   else:
       # æ— äººè„¸æ—¶å±…ä¸­è£å‰ª
       dim = min(w, h)
       img_cropped = img_pil.crop(((w-dim)//2, (h-dim)//2, (w+dim)//2, (h+dim)//2))
   # C. æ ¸å¿ƒåƒç´ æ˜ å°„é€»è¾‘
   # ç¼©æ”¾è‡³ 48x48 ä¹é«˜ç½‘æ ¼
   img_small = img_cropped.resize((grid_res, grid_res), Image.Resampling.LANCZOS)
   pixel_array = np.array(img_small)
   # åœ¨å°å›¾ä¸Šå†æ¬¡ç¡®å®šäººè„¸ ROIï¼Œé˜²æ­¢èƒŒæ™¯å¹²æ‰°
   small_cv = cv2.cvtColor(pixel_array, cv2.COLOR_RGB2BGR)
   small_faces = load_cascade().detectMultiScale(cv2.cvtColor(small_cv, cv2.COLOR_BGR2GRAY), 1.05, 1)
   face_mask = np.zeros((grid_res, grid_res), dtype=bool)
   if len(small_faces) > 0:
       for (sx, sy, sw, sh) in small_faces:
           face_mask[sy:sy+sh, sx:sx+sw] = True
   # åˆå§‹åŒ–è¿è¡Œåº“å­˜å‰¯æœ¬
   run_inv = {k: [list(v[0]), v[1]] for k, v in LEGO_INVENTORY.items()}
   canvas = np.zeros((grid_res, grid_res, 3), dtype=np.uint8)
   # æ¸²æŸ“æ¯ä¸€ä¸ªç½‘æ ¼ç‚¹
   for y in range(grid_res):
       for x in range(grid_res):
           is_face_pixel = face_mask[y, x]
           rgb, _ = get_best_color(
               pixel_array[y, x],
               run_inv,
               is_face_roi=is_face_pixel,
               dither_rate=skin_dither
           )
           canvas[y, x] = rgb
   # D. ç»“æœå±•ç¤º
   col1, col2 = st.columns(2)
   with col1:
       st.image(img_cropped, caption="å›¾åƒé¢„å¤„ç†é¢„è§ˆ", use_container_width=True)
   with col2:
       res_img = Image.fromarray(canvas)
       # å±•ç¤ºæ”¾å¤§åçš„åƒç´ æ•ˆæœ
       st.image(res_img.resize((600, 600), Image.Resampling.NEAREST),
                caption="ä¹é«˜ 48x48 è‰ºæœ¯è½¬æ¢ç»“æœ", use_container_width=True)
   # E. åº“å­˜å®æ—¶ç›‘æ§è¡¨
   with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†é›¶ä»¶æ¶ˆè€— (ä¸¥æ ¼åŸºäº 31205 åº“å­˜)"):
       stats = []
       for name, original in LEGO_INVENTORY.items():
           used = original[1] - run_inv[name][1]
           stats.append({"é¢œè‰²": name, "å·²ç”¨æ•°é‡": used, "åº“å†…å‰©ä½™": run_inv[name][1]})
       st.table(stats)
