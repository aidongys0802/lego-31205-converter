import streamlit as st
import numpy as np
import cv2
from PIL import Image, ImageEnhance
# --- 1. åŸºç¡€é…ç½®ä¸ä¹é«˜æ•°æ® ---
st.set_page_config(page_title="LEGO 31205 å®šåˆ¶ä¼˜åŒ–ç‰ˆ", layout="wide")
LEGO_31205_DATA = {
   "Black": [(0, 0, 0), 600], "Dark Stone Grey": [(99, 95, 97), 470],
   "Medium Stone Grey": [(150, 152, 152), 370], "White": [(255, 255, 255), 350],
   "Navy Blue": [(27, 42, 52), 310], "Blue": [(0, 85, 191), 280],
   "Medium Azure": [(0, 174, 216), 170], "Light Aqua": [(188, 225, 233), 140],
   "Tan": [(217, 187, 123), 140], "Flesh (Light Nougat)": [(255, 158, 146), 140],
   "Dark Orange": [(168, 84, 9), 110], "Reddish Brown": [(127, 51, 26), 100],
   "Red": [(215, 0, 0), 100], "Medium Lavender": [(156, 124, 204), 100],
   "Sand Blue": [(112, 129, 154), 100]
}
@st.cache_resource
def load_face_cascade():
   return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
# --- 2. æ ¸å¿ƒç®—æ³•ç»„ä»¶ ---
def get_closest_color_info(target_rgb, inventory):
   """æ‰¾åˆ°æœ€æ¥è¿‘çš„é¢œè‰²"""
   tr, tg, tb = target_rgb
   best_dist = float('inf')
   best_key = "Black"
   # åªæŸ¥æ‰¾ï¼Œä¸æ‰£åº“å­˜
   for name, data in inventory.items():
       (r, g, b), count = data
       if count > 0:
           dist = (r - tr)**2 + (g - tg)**2 + (b - tb)**2
           if dist < best_dist:
               best_dist = dist
               best_key = name
   return inventory[best_key][0], best_key
def detect_face_rect(pil_img):
   """åœ¨å›¾ç‰‡ä¸Šæ£€æµ‹æœ€å¤§äººè„¸çš„çŸ©å½¢åŒºåŸŸ"""
   face_cascade = load_face_cascade()
   cv_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
   gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)
   faces = face_cascade.detectMultiScale(gray, 1.1, 4)
   if len(faces) > 0:
       # è¿”å›æœ€å¤§çš„è„¸
       return sorted(faces, key=lambda x: x[2]*x[3], reverse=True)[0]
   return None
def smart_crop_by_rect(pil_img, face_rect, zoom_level=1.5):
   """åŸºäºç»™å®šçš„äººè„¸çŸ©å½¢è¿›è¡Œæ™ºèƒ½è£å‰ª"""
   w, h = pil_img.size
   if face_rect is not None:
       fx, fy, fw, fh = face_rect
       cx, cy = fx + fw // 2, fy + fh // 2
       crop_dim = int(max(fw, fh) * zoom_level)
       x1 = max(0, cx - crop_dim // 2)
       y1 = max(0, cy - crop_dim // 2)
       x2 = min(w, cx + crop_dim // 2)
       y2 = min(h, cy + crop_dim // 2)
       final_dim = min(x2 - x1, y2 - y1)
       return pil_img.crop((x1, y1, x1+final_dim, y1+final_dim))
   else:
       dim = min(w, h)
       left, top = (w - dim) // 2, (h - dim) // 2
       return pil_img.crop((left, top, left + dim, top + dim))
def generate_face_mask_lowres(pil_img_cropped, grid_size):
   """ç”Ÿæˆä¸€ä¸ªä½åˆ†è¾¨ç‡çš„ Maskï¼Œç™½è‰²è¡¨ç¤ºäººè„¸æ ¸å¿ƒåŒºåŸŸ"""
   # 1. åœ¨é«˜åˆ†è¾¨ç‡è£å‰ªå›¾ä¸Šå†æ¬¡å®šä½äººè„¸
   face_rect = detect_face_rect(pil_img_cropped)
   # åˆ›å»ºå…¨é»‘é«˜åˆ† Mask
   mask_hr_np = np.zeros((pil_img_cropped.size[1], pil_img_cropped.size[0]), dtype=np.uint8)
   if face_rect is not None:
       fx, fy, fw, fh = face_rect
       # ç¨å¾®å‘å†…æ”¶ç¼©ä¸€ç‚¹ï¼Œåªä¿æŠ¤æ ¸å¿ƒäº”å®˜åŒºåŸŸä¸æŠ–åŠ¨ï¼Œè¾¹ç¼˜å¯ä»¥ç¨å¾®è¿‡æ¸¡
       inset_x = int(fw * 0.15)
       inset_y = int(fh * 0.1)
       # åœ¨ Mask ä¸Šç»˜åˆ¶ç™½è‰²å®å¿ƒçŸ©å½¢
       cv2.rectangle(mask_hr_np, (fx+inset_x, fy+inset_y), (fx+fw-inset_x, fy+fh-inset_y), 255, -1)
   mask_hr_img = Image.fromarray(mask_hr_np)
   # 2. ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ç¼©æ”¾åˆ°ç½‘æ ¼å°ºå¯¸ï¼Œä¿è¯è¾¹ç¼˜é”åˆ©
   mask_lr_img = mask_hr_img.resize((grid_size, grid_size), Image.Resampling.NEAREST)
   return np.array(mask_lr_img)
def apply_selective_dithering(pixel_array, face_mask_array, inventory, use_dithering_bg=True):
   """åº”ç”¨é€‰æ‹©æ€§æŠ–åŠ¨ï¼šäººè„¸åŒºåŸŸå¼ºåˆ¶å¹³æ»‘ï¼ŒèƒŒæ™¯å¯é€‰æŠ–åŠ¨"""
   h, w, _ = pixel_array.shape
   buffer = pixel_array.astype(float)
   output = np.zeros_like(pixel_array)
   stats = {}
   temp_inv = {k: [list(v[0]), v[1]] for k, v in inventory.items()}
   for y in range(h):
       for x in range(w):
           old_pixel = buffer[y, x]
           # å¦‚æœ mask å¯¹åº”ä½ç½®æ˜¯ç™½è‰² (255)ï¼Œåˆ™æ˜¯äººè„¸ä¿æŠ¤åŒº
           is_face_protected = face_mask_array[y, x] > 128
           new_pixel, name = get_closest_color_info(old_pixel, temp_inv)
           output[y, x] = new_pixel
           stats[name] = stats.get(name, 0) + 1
           temp_inv[name][1] -= 1
           # å…³é”®é€»è¾‘ï¼šåªæœ‰å½“ (å¼€å¯äº†èƒŒæ™¯æŠ–åŠ¨) ä¸” (å½“å‰åƒç´ ä¸åœ¨äººè„¸ä¿æŠ¤åŒº) æ—¶ï¼Œæ‰æ‰©æ•£è¯¯å·®
           if use_dithering_bg and not is_face_protected:
               quant_error = old_pixel - new_pixel
               if x + 1 < w: buffer[y, x + 1] += quant_error * 7 / 16
               if y + 1 < h:
                   if x - 1 >= 0: buffer[y + 1, x - 1] += quant_error * 3 / 16
                   buffer[y + 1, x] += quant_error * 5 / 16
                   if x + 1 < w: buffer[y + 1, x + 1] += quant_error * 1 / 16
   return output, stats
# --- 3. ç•Œé¢ä¸»é€»è¾‘ ---
st.title("ğŸ§© LEGO 31205 äººåƒå®šåˆ¶ä¼˜åŒ–ç‰ˆ")
st.markdown("**ä¼˜åŒ–é‡ç‚¹ï¼šäººè„¸åŒºåŸŸæ— æŠ–åŠ¨ã€è‚¤è‰²ç»Ÿä¸€ã€äº”å®˜æ¸…æ™°ã€‚**")
with st.sidebar:
   st.header("ğŸ›ï¸ å‚æ•°é¢æ¿")
   grid_size = st.select_slider("ç”»å¸ƒåˆ†è¾¨ç‡ (Grid Size)", options=[32, 48, 64], value=48)
   st.subheader("1. æ„å›¾ä¸é¢„å¤„ç†")
   zoom_factor = st.slider("äººè„¸ç‰¹å†™ç¨‹åº¦ (æ•°å€¼è¶Šå°è„¸è¶Šå¤§)", 1.3, 3.0, 2.0)
   contrast = st.slider("å¯¹æ¯”åº¦å¢å¼º (æé«˜æ¸…æ™°åº¦)", 0.8, 1.8, 1.3, help="å¢åŠ å¯¹æ¯”åº¦æœ‰åŠ©äºè®©äº”å®˜ä¸è‚¤è‰²åˆ†ç¦»å¾—æ›´æ¸…æ™°")
   brightness = st.slider("äº®åº¦è°ƒæ•´ (ä½¿è‚¤è‰²æ›´æµ…)", 0.8, 1.5, 1.1, help="é€‚å½“æé«˜äº®åº¦å¯ä»¥è®©è‚¤è‰²åŒ¹é…åˆ°æ›´æµ…çš„ç§¯æœ¨")
   st.subheader("2. è´¨æ„Ÿæ§åˆ¶")
   use_dithering_bg = st.checkbox("èƒŒæ™¯å¼€å¯æŠ–åŠ¨è´¨æ„Ÿ", value=True, help="äººè„¸åŒºåŸŸå°†å§‹ç»ˆä¿æŒå…‰æ»‘ç»Ÿä¸€ï¼Œæ­¤é€‰é¡¹ä»…å½±å“èƒŒæ™¯å’Œè¡£æœã€‚")
uploaded_file = st.file_uploader("ä¸Šä¼ ç…§ç‰‡ (å»ºè®®é¢éƒ¨å…‰çº¿å‡åŒ€)", type=["jpg", "png", "jpeg"])
if uploaded_file:
   # 1. åŠ è½½ä¸é¢„å¤„ç†
   original = Image.open(uploaded_file).convert("RGB")
   # è°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦
   enhancer_bri = ImageEnhance.Brightness(original)
   img_bri = enhancer_bri.enhance(brightness)
   enhancer_con = ImageEnhance.Contrast(img_bri)
   img_processed = enhancer_con.enhance(contrast)
   # 2. æ™ºèƒ½æ£€æµ‹ä¸è£å‰ª
   face_rect_raw = detect_face_rect(img_processed)
   img_cropped = smart_crop_by_rect(img_processed, face_rect_raw, zoom_level=zoom_factor)
   col1, col2 = st.columns(2)
   with col1:
       st.image(img_cropped, caption="é¢„å¤„ç†ä¸è£å‰ªç»“æœ", use_container_width=True)
   if st.button("ç”Ÿæˆå®šåˆ¶ä¹é«˜ç”»"):
       with st.spinner("æ­£åœ¨è¿›è¡Œåˆ†åŒºçº¹ç†å¤„ç†..."):
           # 3. ç”Ÿæˆäººè„¸ä¿æŠ¤ Mask (ä½åˆ†è¾¨ç‡)
           face_mask_lr = generate_face_mask_lowres(img_cropped, grid_size)
           # Debug: å–æ¶ˆä¸‹é¢æ³¨é‡Šå¯ä»¥é¢„è§ˆäººè„¸ä¿æŠ¤åŒºåŸŸ
           # st.image(Image.fromarray(face_mask_lr), caption="äººè„¸ä¿æŠ¤åŒºé¢„è§ˆ(ç™½è‰²åŒºåŸŸä¸æŠ–åŠ¨)", width=200)
           # 4. ç¼©æ”¾å›¾åƒå¹¶åº”ç”¨é€‰æ‹©æ€§æŠ–åŠ¨
           img_small = img_cropped.resize((grid_size, grid_size), Image.Resampling.LANCZOS)
           pixel_data = np.array(img_small)
           final_array, usage = apply_selective_dithering(
               pixel_data, face_mask_lr, LEGO_31205_DATA, use_dithering_bg
           )
           result_img = Image.fromarray(final_array.astype('uint8'))
           with col2:
               st.image(result_img.resize((600, 600), Image.Resampling.NEAREST),
                        caption="æœ€ç»ˆæ•ˆæœ (äººè„¸å…‰æ»‘ä¼˜åŒ–)", use_container_width=True)
           st.success("ç”Ÿæˆå®Œæˆï¼è„¸éƒ¨åŒºåŸŸå·²è‡ªåŠ¨å‡€åŒ–å™ªç‚¹ã€‚")
           with st.expander("æŸ¥çœ‹é›¶ä»¶æ¶ˆè€—æ¸…å•"):
               sorted_usage = sorted(usage.items(), key=lambda x: x[1], reverse=True)
               st.table([{"é›¶ä»¶é¢œè‰²": k, "ä½¿ç”¨æ•°é‡": v, "åº“å­˜å‰©ä½™": LEGO_31205_DATA[k][1]-v} for k, v in sorted_usage])
