import streamlit as st
import cv2
import numpy as np
from PIL import Image
import math
# --- 1. é…ç½®ä¸ä¹é«˜ 31205 æ•°æ® ---
st.set_page_config(page_title="LEGO 31205 äººåƒè½¬æ¢å™¨ (OpenCV ç¨³å®šç‰ˆ)", layout="wide")
# ä¹é«˜ 31205 (è™è ä¾ ) é›¶ä»¶åˆ—è¡¨ï¼šé¢œè‰²åç§° -> [(R, G, B), æ•°é‡]
LEGO_31205_DATA = {
   "Black": [(0, 0, 0), 600],
   "Dark Stone Grey": [(99, 95, 97), 470],
   "Medium Stone Grey": [(150, 152, 152), 370],
   "White": [(255, 255, 255), 350],
   "Navy Blue": [(27, 42, 52), 310],
   "Blue": [(0, 85, 191), 280],
   "Medium Azure": [(0, 174, 216), 170],
   "Light Aqua": [(188, 225, 233), 140],
   "Tan": [(217, 187, 123), 140],
   "Flesh (Light Nougat)": [(255, 158, 146), 140],
   "Dark Orange": [(168, 84, 9), 110],
   "Reddish Brown": [(127, 51, 26), 100],
   "Red": [(215, 0, 0), 100],
   "Medium Lavender": [(156, 124, 204), 100],
   "Sand Blue": [(112, 129, 154), 100]
}
# ä½¿ç”¨ OpenCV è‡ªå¸¦çš„äººè„¸æ£€æµ‹æ¨¡å‹
@st.cache_resource
def load_face_cascade():
   # è·å– OpenCV è‡ªå¸¦çš„åˆ†ç±»å™¨è·¯å¾„
   cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
   return cv2.CascadeClassifier(cascade_path)
# --- 2. æ ¸å¿ƒç®—æ³•é€»è¾‘ ---
def get_closest_available(target_rgb, inventory):
   r, g, b = target_rgb
   candidates = []
   for name, data in inventory.items():
       rgb, count = data
       if count > 0:
           # è®¡ç®—æ¬§å¼è·ç¦»ï¼Œæ‰¾åˆ°æœ€æ¥è¿‘çš„é¢œè‰²
           dist = math.sqrt((r - rgb[0])**2 + (g - rgb[1])**2 + (b - rgb[2])**2)
           candidates.append((dist, name))
   if not candidates:
       return (0, 0, 0), "Black" # å¦‚æœæ‰€æœ‰é¢œè‰²çš„åº“å­˜éƒ½ç”¨å…‰äº†ï¼Œè¿”å›é»‘è‰²
   candidates.sort()
   best_name = candidates[0][1]
   inventory[best_name][1] -= 1 # æ¶ˆè€—ä¸€ä¸ªé›¶ä»¶
   return inventory[best_name][0], best_name
def process_image(pil_img, size, p_weights):
   face_cascade = load_face_cascade()
   # è½¬æ¢ä¸º RGB å’Œ Gray
   img_rgb = np.array(pil_img.convert("RGB"))
   # è®¡ç®—è£å‰ªåæ ‡ï¼Œå°†å›¾ç‰‡ä¸­å¿ƒè£å‰ªä¸ºæ­£æ–¹å½¢
   h, w, _ = img_rgb.shape
   crop_size = min(h, w)
   y0, x0 = (h - crop_size)//2, (w - crop_size)//2
   # è£å‰ªå¹¶ç¼©æ”¾
   cropped_rgb = img_rgb[y0:y0+crop_size, x0:x0+crop_size]
   # åœ¨è£å‰ªåçš„å›¾ç‰‡ä¸Šè¿›è¡Œäººè„¸æ£€æµ‹
   cropped_gray = cv2.cvtColor(cropped_rgb, cv2.COLOR_RGB2GRAY)
   faces = face_cascade.detectMultiScale(cropped_gray, 1.1, 4)
   # å°†å›¾ç‰‡ç¼©æ”¾åˆ°ç”»å¸ƒå°ºå¯¸ï¼ˆä¾‹å¦‚ 48x48ï¼‰
   # OpenCV resize é»˜è®¤è¾“å‡º BGR æ ¼å¼
   img_s_bgr = cv2.resize(cropped_rgb, (size, size), interpolation=cv2.INTER_AREA)
   # --- å…³é”®ä¿®å¤ï¼šå°† BGR è½¬æ¢ä¸º RGB ---
   img_s_rgb = cv2.cvtColor(img_s_bgr, cv2.COLOR_BGR2RGB)
   # ç”¨äºè®¡ç®—äº®åº¦çš„ HSV å›¾åƒ
   img_hsv = cv2.cvtColor(img_s_rgb, cv2.COLOR_RGB2HSV)
   pixel_tasks = []
   for y in range(size):
       for x in range(size):
           # å°†å½“å‰åƒç´ åæ ‡æ˜ å°„å›åŸå›¾æ¯”ä¾‹ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨è„¸éƒ¨æ¡†å†…
           rel_x, rel_y = (x / size) * crop_size, (y / size) * crop_size
           is_face = False
           for (fx, fy, fw, fh) in faces:
               if fx <= rel_x <= fx + fw and fy <= rel_y <= fy + fh:
                   is_face = True
                   break
           v_val = img_hsv[y, x, 2] # è·å–äº®åº¦å€¼ V
           if is_face:
               score = p_weights['face']
           elif v_val > 200:
               score = p_weights['bg_high']
           elif v_val < 50:
               score = p_weights['bg_dark']
           else:
               score = p_weights['bg_normal']
           # è¿™é‡Œçš„ img_s_rgb[y, x] ç°åœ¨æ˜¯æ­£ç¡®çš„ RGB é¢œè‰²
           pixel_tasks.append({'pos':(x,y), 'rgb':img_s_rgb[y,x], 'score':score})
   # æ ¹æ®ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆåˆ†é…é‡è¦åŒºåŸŸçš„é¢œè‰²
   pixel_tasks.sort(key=lambda t: t['score'], reverse=True)
   # å¤åˆ¶ä¸€ä»½åº“å­˜æ•°æ®ç”¨äºè®¡ç®—
   curr_inv = {k: [v[0], v[1]] for k, v in LEGO_31205_DATA.items()}
   res_pixels = {}
   usage = {}
   for task in pixel_tasks:
       rgb, name = get_closest_available(task['rgb'], curr_inv)
       res_pixels[task['pos']] = rgb
       usage[name] = usage.get(name, 0) + 1
   # ç”Ÿæˆæœ€ç»ˆçš„ä¹é«˜é¢„è§ˆå›¾
   out_img = Image.new("RGB", (size, size))
   pix = out_img.load()
   for pos, rgb in res_pixels.items():
       pix[pos[0], pos[1]] = tuple(map(int, rgb))
   return out_img, usage
# --- 3. ç•Œé¢å¸ƒå±€ (ä¿æŒä¸€è‡´) ---
st.title("ğŸ§© LEGO 31205 è‰ºæœ¯ç”»è½¬æ¢å™¨ (OpenCV ç¨³å®šç‰ˆ)")
with st.sidebar:
   st.header("âš™ï¸ å‚æ•°è®¾ç½®")
   grid_size = st.slider("ç”»å¸ƒå°ºå¯¸ (é¢—ç²’æ•°)", 16, 128, 48)
   w_face = st.number_input("äººç‰©é¢éƒ¨ä¼˜å…ˆçº§", value=2000)
   w_high = st.number_input("èƒŒæ™¯é«˜å…‰ä¼˜å…ˆçº§", value=500)
   w_normal = st.number_input("èƒŒæ™¯æ™®é€šä¼˜å…ˆçº§", value=200)
   w_dark = st.number_input("èƒŒæ™¯é˜´å½±ä¼˜å…ˆçº§", value=100)
uploaded_file = st.file_uploader("é€‰æ‹©ç…§ç‰‡...", type=["jpg", "jpeg", "png"])
if uploaded_file:
   image = Image.open(uploaded_file)
   col1, col2 = st.columns(2)
   with col1:
       st.image(image, caption="åŸå§‹ç…§ç‰‡", use_container_width=True)
   if st.button("ç”Ÿæˆä¹é«˜ç”»"):
       p_weights = {'face': w_face, 'bg_high': w_high, 'bg_normal': w_normal, 'bg_dark': w_dark}
       result_img, usage_stats = process_image(image, grid_size, p_weights)
       with col2:
           # ä½¿ç”¨ Nearest Neighbor æ’å€¼æ”¾å¤§ï¼Œä¿æŒåƒç´ æ„Ÿ
           st.image(result_img.resize((600, 600), resample=0), caption="é¢„è§ˆ", use_container_width=True)
       st.subheader("ğŸ“Š é›¶ä»¶æ¶ˆè€—")
       cols = st.columns(3)
       for i, (name, count) in enumerate(usage_stats.items()):
           original_stock = LEGO_31205_DATA[name][1]
           cols[i % 3].metric(name, f"{count} é¢—", f"å‰©ä½™ {original_stock - count}")
