import streamlit as st
import numpy as np
import cv2
from PIL import Image, ImageEnhance
st.set_page_config(page_title="LEGO 31205 ç»ˆæè´¨æ„Ÿç‰ˆ", layout="wide")
# 1. LEGO 31205 ä¸¥æ ¼åº“å­˜
def get_inventory():
   return {
       "Black": [(0, 0, 0), 600], "Dark Stone Grey": [(99, 95, 97), 470],
       "Medium Stone Grey": [(150, 152, 152), 370], "White": [(255, 255, 255), 350],
       "Navy Blue": [(27, 42, 52), 310], "Blue": [(0, 85, 191), 280],
       "Medium Azure": [(0, 174, 216), 170], "Light Aqua": [(188, 225, 233), 140],
       "Tan": [(217, 187, 123), 140], "Flesh": [(255, 158, 146), 140],
       "Dark Orange": [(168, 84, 9), 110], "Reddish Brown": [(127, 51, 26), 100],
       "Red": [(215, 0, 0), 100], "Medium Lavender": [(156, 124, 204), 100],
       "Sand Blue": [(112, 129, 154), 100]
   }
# 2. æ ¸å¿ƒç®—æ³•ï¼šå¸¦åŒºåŸŸæƒé‡çš„åŠ æƒè·ç¦»è®¡ç®—
def find_best_match_weighted(target_pixel, inv, is_face):
   tr, tg, tb = target_pixel
   best_dist = float('inf')
   best_name = None
   for name, (rgb, count) in inv.items():
       if count <= 0: continue
       # 1. åŸºç¡€è‰²å½©è·ç¦» (åŠ æƒæ¬§æ°è·ç¦»ï¼Œäººçœ¼å¯¹ç»¿è‰²æ›´æ•æ„Ÿ)
       dr, dg, db = rgb[0] - tr, rgb[1] - tg, rgb[2] - tb
       dist = 2*dr**2 + 4*dg**2 + 3*db**2
       # 2. åŒºåŸŸæƒé‡ç­–ç•¥ (æ ¸å¿ƒé­”æ³•)
       if is_face:
           # --- é¢éƒ¨ç­–ç•¥ ---
           # æåº¦é¼“åŠ± Tan å’Œ White æ··åˆï¼Œæ¨¡ä»¿å‚è€ƒå›¾çš„é«˜å…‰è´¨æ„Ÿ
           if name == "White": dist *= 0.5   # ç–¯ç‹‚æ‰“æŠ˜
           elif name == "Tan": dist *= 0.6   # æ‰“æŠ˜
           elif name == "Flesh": dist *= 0.9 # ç¨å¾®ä¼˜å…ˆï¼Œåšå¦†å®¹
           # é¼“åŠ±æ·±è‰²ç”¨äºäº”å®˜å‹¾å‹’
           elif name in ["Black", "Dark Stone Grey", "Reddish Brown"]: dist *= 1.0
           # æƒ©ç½šå†·è‰²è°ƒï¼Œé˜²æ­¢è„¸å‘é’
           elif name in ["Light Aqua", "Blue", "Medium Azure"]: dist *= 2.0
       else:
           # --- èƒŒæ™¯ç­–ç•¥ ---
           # ä¸¥ç¦èƒŒæ™¯æŠ¢èµ°å®è´µçš„çš®è‚¤ç§¯æœ¨
           if name in ["Flesh", "Tan"]: dist *= 50.0
           # èƒŒæ™¯å°½é‡ä¸ç”¨ç™½è‰²ï¼Œé™¤éä¸‡ä¸å¾—å·²
           if name == "White": dist *= 10.0
           # å¼ºåˆ¶èƒŒæ™¯å€¾å‘äºå†·è‰²è°ƒæµ…è‰² (Light Aqua, Grey)
           if name in ["Light Aqua", "Medium Stone Grey", "Sand Blue"]: dist *= 0.6
       if dist < best_dist:
           best_dist = dist
           best_name = name
   if best_name:
       inv[best_name][1] -= 1
       return inv[best_name][0], best_name
   return (0, 0, 0), "Black"
# --- UI ---
st.sidebar.header("ğŸ¨ å‚è€ƒå›¾å¤åˆ»è°ƒèŠ‚")
st.sidebar.markdown("**æ ¸å¿ƒè°ƒèŠ‚æŒ‡å—ï¼š**\n* æƒ³è¦å›¾ä¾‹é‚£ç§ç™½ç‚¹å¤šçš„æ•ˆæœï¼Œè¯·è°ƒé«˜äº®åº¦ã€‚\n* æƒ³è¦äº”å®˜æ¸…æ™°ï¼Œè¯·è°ƒé«˜å¯¹æ¯”åº¦ã€‚")
brightness_val = st.sidebar.slider("1. äº®åº¦ (æ§åˆ¶é«˜å…‰Whiteå æ¯”)", 0.5, 2.5, 1.3)
contrast_val = st.sidebar.slider("2. å¯¹æ¯”åº¦ (æ§åˆ¶Tan/Whiteåˆ†ç¦»)", 0.5, 3.0, 1.6)
dither_strength = st.sidebar.slider("3. æŠ–åŠ¨å¼ºåº¦ (é¢—ç²’æ„Ÿ)", 0.0, 1.0, 0.9, help="è¶Šæ¥è¿‘1.0ï¼Œé¢—ç²’æ„Ÿè¶Šå¼ºï¼Œè¶Šåƒå‚è€ƒå›¾")
zoom_val = st.sidebar.slider("4. äººè„¸ç¼©æ”¾", 1.0, 3.0, 1.8)
uploaded_file = st.file_uploader("ä¸Šä¼ ç…§ç‰‡", type=["jpg", "png", "jpeg"])
if uploaded_file:
   # A. å›¾åƒå¢å¼º
   img = Image.open(uploaded_file).convert("RGB")
   img = ImageEnhance.Brightness(img).enhance(brightness_val)
   img = ImageEnhance.Contrast(img).enhance(contrast_val)
   # B. æ™ºèƒ½è£å‰ª (ä¿æŒæ­£æ–¹å½¢)
   w, h = img.size
   crop_dim = int(min(w, h) / zoom_val)
   # å°è¯•æ£€æµ‹äººè„¸ä»¥ä¸­å¿ƒå¯¹é½
   cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
   face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
   faces = face_cascade.detectMultiScale(cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY), 1.1, 4)
   if len(faces) > 0:
       fx, fy, fw, fh = max(faces, key=lambda x: x[2]*x[3]) # å–æœ€å¤§äººè„¸
       cx, cy = fx + fw//2, fy + fh//2
   else:
       cx, cy = w//2, h//2
   left = max(0, min(w - crop_dim, cx - crop_dim // 2))
   top = max(0, min(h - crop_dim, cy - crop_dim // 2))
   img_cropped = img.crop((left, top, left + crop_dim, top + crop_dim))
   # C. ç¼©æ”¾è‡³ 48x48 å¹¶è½¬ä¸º Float è¿›è¡Œè®¡ç®—
   small = img_cropped.resize((48, 48), Image.Resampling.LANCZOS)
   pixel_buffer = np.array(small, dtype=float)
   # D. ç”Ÿæˆ Mask (å†æ¬¡åœ¨å°å›¾ä¸Šç¡®è®¤äººè„¸åŒºåŸŸ)
   small_cv = cv2.cvtColor(np.array(small), cv2.COLOR_RGB2BGR)
   small_faces = face_cascade.detectMultiScale(cv2.cvtColor(small_cv, cv2.COLOR_BGR2GRAY), 1.05, 1)
   face_mask = np.zeros((48, 48), dtype=bool)
   if len(small_faces) > 0:
       for (fx, fy, fw, fh) in small_faces:
           # ç¨å¾®æ‰©å¤§ä¸€ç‚¹ mask èŒƒå›´ï¼Œä¿è¯è„¸é¢Šè¾¹ç¼˜ä¹Ÿè¢«è¦†ç›–
           pad = 1
           face_mask[max(0,fy-pad):min(48,fy+fh+pad), max(0,fx-pad):min(48,fx+fw+pad)] = True
   else:
       # å…œåº•ï¼šå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ï¼Œå‡è®¾ä¸­é—´ 50% æ˜¯è„¸
       face_mask[12:36, 12:36] = True
   # E. Floyd-Steinberg è¯¯å·®æ‰©æ•£å¾ªç¯
   current_inv = get_inventory()
   canvas = np.zeros((48, 48, 3), dtype=np.uint8)
   for y in range(48):
       for x in range(48):
           # 1. è¯»å–å½“å‰åƒç´  (å«ä¹‹å‰ä¼ é€’è¿‡æ¥çš„è¯¯å·®)
           old_val = np.clip(pixel_buffer[y, x], 0, 255)
           # 2. å¯»æ‰¾æœ€ä½³ç§¯æœ¨ (åº”ç”¨åŒºåŸŸæƒé‡)
           is_face_pixel = face_mask[y, x]
           new_rgb, name = find_best_match_weighted(old_val, current_inv, is_face_pixel)
           # 3. å¡«å…¥ç”»å¸ƒ
           canvas[y, x] = new_rgb
           # 4. è®¡ç®—è¯¯å·®
           error = (old_val - new_rgb) * dither_strength
           # 5. æ‰©æ•£è¯¯å·® (Floyd-Steinberg çŸ©é˜µ)
           #       X   7
           #   3   5   1
           if x + 1 < 48:
               pixel_buffer[y, x + 1] += error * 7 / 16
           if y + 1 < 48:
               if x - 1 >= 0:
                   pixel_buffer[y + 1, x - 1] += error * 3 / 16
               pixel_buffer[y + 1, x] += error * 5 / 16
               if x + 1 < 48:
                   pixel_buffer[y + 1, x + 1] += error * 1 / 16
   # F. å±•ç¤ºç»“æœ
   col1, col2 = st.columns(2)
   with col1:
       st.image(img_cropped, caption="è£åˆ‡é¢„è§ˆ", use_container_width=True)
   with col2:
       res_img = Image.fromarray(canvas)
       st.image(res_img.resize((600, 600), Image.Resampling.NEAREST), caption="æœ€ç»ˆæ•ˆæœ", use_container_width=True)
   # G. æ¶ˆè€—ç»Ÿè®¡
   with st.expander("ğŸ“Š 31205 åº“å­˜å®æ—¶ç›‘æ§"):
       raw_inv = get_inventory()
       stats = []
       # åˆ†ç±»å±•ç¤º
       face_colors = ["White", "Tan", "Flesh", "Dark Orange"]
       bg_colors = ["Light Aqua", "Medium Stone Grey", "Sand Blue", "Blue"]
       st.write("**æ ¸å¿ƒè‚¤è‰²æ¶ˆè€—:**")
       cols = st.columns(len(face_colors))
       for idx, k in enumerate(face_colors):
           used = raw_inv[k][1] - current_inv[k][1]
           cols[idx].metric(k, f"{used}/{raw_inv[k][1]}", delta=current_inv[k][1])
       st.write("**èƒŒæ™¯æ›¿ä»£è‰²æ¶ˆè€—:**")
       cols2 = st.columns(len(bg_colors))
       for idx, k in enumerate(bg_colors):
           used = raw_inv[k][1] - current_inv[k][1]
           cols2[idx].metric(k, f"{used}/{raw_inv[k][1]}", delta=current_inv[k][1])
