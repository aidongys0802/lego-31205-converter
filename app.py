import os
import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from mediapipe.solutions import selfie_segmentation as mp_selfie_seg
from mediapipe.solutions import face_detection as mp_face_det
from PIL import Image
import math
# --- 1. é…ç½®ä¸Žä¹é«˜ 31205 æ•°æ® ---
st.set_page_config(page_title="LEGO 31205 äººåƒè½¬æ¢å™¨", layout="wide")
LEGO_31205_DATA = {
   "Black": [(0, 0, 0), 600],
   "Dark Stone Grey": [(99, 95, 97), 470],
   "Medium Stone Grey": [(150, 152, 152), 370],
   "White": [(255, 255, 255), 350],
   "Navy Blue": [(27, 42, 52), 310],
   "Blue": [(0, 85, 191), 280],
   "Medium Azure": [(0, 174, 216), 170],
   "Light Aqua": [(188, 225, 233), 140],
   "Tan": [(217, 187, 123), 140],
   "Flesh (Light Nougat)": [(255, 158, 146), 140],
   "Dark Orange": [(168, 84, 9), 110],
   "Reddish Brown": [(127, 51, 26), 100],
   "Red": [(215, 0, 0), 100],
   "Medium Lavender": [(156, 124, 204), 100],
   "Sand Blue": [(112, 129, 154), 100]
}
# åˆå§‹åŒ–æ¨¡åž‹ (æ˜¾å¼å¯¼å…¥å­æ¨¡å—ä»¥å¢žå¼ºå…¼å®¹æ€§)
@st.cache_resource
def load_models():
   mp_selfie = mp_selfie_seg.SelfieSegmentation(model_selection=1)
   mp_face = mp_face_det.FaceDetection(model_selection=1, min_detection_confidence=0.5)
   return mp_selfie, mp_face
# --- 2. æ ¸å¿ƒç®—æ³•é€»è¾‘ ---
def get_closest_available(target_rgb, inventory):
   r, g, b = target_rgb
   candidates = []
   for name, data in inventory.items():
       rgb, count = data
       if count > 0:
           # ç®€å•çš„æ¬§å¼è·ç¦»è®¡ç®—é¢œè‰²æŽ¥è¿‘åº¦
           dist = math.sqrt((r - rgb[0])**2 + (g - rgb[1])**2 + (b - rgb[2])**2)
           candidates.append((dist, name))
   if not candidates:
       return (0, 0, 0), "Black"
   candidates.sort()
   best_name = candidates[0][1]
   inventory[best_name][1] -= 1  # æ¶ˆè€—ä¸€ä¸ªé›¶ä»¶
   return inventory[best_name][0], best_name
def process_image(pil_img, size, p_weights):
   mp_selfie, mp_face = load_models()
   # å¼ºåˆ¶è½¬æ¢ä¸º RGB Numpy æ•°ç»„
   img_rgb = np.array(pil_img.convert("RGB"))
   if img_rgb is None or img_rgb.size == 0:
       return None, None
   h, w, _ = img_rgb.shape
   # å±…ä¸­è£å‰ªæˆæ­£æ–¹å½¢
   crop_size = min(h, w)
   y0, x0 = (h - crop_size)//2, (w - crop_size)//2
   cropped_img = img_rgb[y0:y0+crop_size, x0:x0+crop_size]
   # AI åˆ†æž (ä½¿ç”¨åŽŸå›¾æˆ–è£å‰ªå›¾)
   res_seg = mp_selfie.process(cropped_img)
   person_mask = res_seg.segmentation_mask # 0-1 ä¹‹é—´çš„æ¦‚çŽ‡å›¾
   res_face = mp_face.process(cropped_img)
   face_boxes = []
   if res_face.detections:
       for det in res_face.detections:
           bbox = det.location_data.relative_bounding_box
           face_boxes.append(bbox)
   # ç¼©æ”¾åˆ°é¢—ç²’åº¦å¤§å°
   img_s = cv2.resize(cropped_img, (size, size), interpolation=cv2.INTER_AREA)
   mask_s = cv2.resize(person_mask, (size, size), interpolation=cv2.INTER_NEAREST)
   if img_s is None or img_s.size == 0:
       return None, None
   img_hsv = cv2.cvtColor(img_s, cv2.COLOR_RGB2HSV)
   # ä¼˜å…ˆçº§è¯„åˆ†
   pixel_tasks = []
   for y in range(size):
       for x in range(size):
           rel_x, rel_y = x / size, y / size
           is_person = mask_s[y, x] > 0.5
           is_face = False
           if is_person:
               for box in face_boxes:
                   if (box.xmin <= rel_x <= box.xmin + box.width and
                       box.ymin <= rel_y <= box.ymin + box.height):
                       is_face = True
                       break
           v_val = img_hsv[y, x, 2] # äº®åº¦
           if is_face: score = p_weights['face']
           elif is_person: score = p_weights['clothes']
           elif v_val > 200: score = p_weights['bg_high']
           elif v_val < 50: score = p_weights['bg_dark']
           else: score = p_weights['bg_normal']
           pixel_tasks.append({'pos':(x,y), 'rgb':img_s[y,x], 'score':score})
   # æ ¹æ®ä¼˜å…ˆçº§æŽ’åºï¼Œä¼˜å…ˆåˆ†é…é‡è¦éƒ¨ä½çš„é›¶ä»¶é¢œè‰²
   pixel_tasks.sort(key=lambda t: t['score'], reverse=True)
   # æ‹·è´ä¸€ä»½åº“å­˜è¿›è¡Œè®¡ç®—
   curr_inv = {k: [v[0], v[1]] for k, v in LEGO_31205_DATA.items()}
   res_pixels = {}
   usage = {}
   for task in pixel_tasks:
       rgb, name = get_closest_available(task['rgb'], curr_inv)
       res_pixels[task['pos']] = rgb
       usage[name] = usage.get(name, 0) + 1
   # ç”Ÿæˆé¢„è§ˆå›¾
   out_img = Image.new("RGB", (size, size))
   pix = out_img.load()
   for pos, rgb in res_pixels.items():
       pix[pos[0], pos[1]] = tuple(map(int, rgb))
   return out_img, usage
# --- 3. ç½‘é¡µç•Œé¢å¸ƒå±€ ---
st.title("ðŸ§© LEGO 31205 è‰ºæœ¯ç”»æ™ºèƒ½ç”Ÿæˆå™¨")
st.markdown("ä¸Šä¼ ç…§ç‰‡ï¼ŒAI å°†è‡ªåŠ¨è¯†åˆ«äººç‰©å¹¶æ ¹æ®ç§¯æœ¨åº“å­˜ä¼˜åŒ–åˆ†é…é¢œè‰²ã€‚")
with st.sidebar:
   st.header("âš™ï¸ å‚æ•°è®¾ç½®")
   grid_size = st.slider("ç”»å¸ƒå°ºå¯¸ (é¢—ç²’æ•°)", 16, 128, 48)
   st.subheader("ä¼˜å…ˆçº§æƒé‡è‡ªå®š")
   w_face = st.number_input("äººç‰©é¢éƒ¨", value=2000)
   w_clothes = st.number_input("äººç‰©è¡£ç€", value=1000)
   w_high = st.number_input("èƒŒæ™¯é«˜å…‰", value=500)
   w_normal = st.number_input("èƒŒæ™¯æ™®é€š", value=200)
   w_dark = st.number_input("èƒŒæ™¯é˜´å½±", value=100)
   st.info("æƒé‡è¶Šé«˜ï¼Œè¯¥åŒºåŸŸè¶Šä¼˜å…ˆåŒ¹é…æœ€æŽ¥è¿‘çš„é¢œè‰²ã€‚")
uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ ç…§ç‰‡...", type=["jpg", "jpeg", "png"])
if uploaded_file is not None:
   image = Image.open(uploaded_file)
   col1, col2 = st.columns(2)
   with col1:
       st.image(image, caption="åŽŸå§‹ç…§ç‰‡", use_container_width=True)
   if st.button("å¼€å§‹ç”Ÿæˆä¹é«˜é¢„è§ˆ"):
       with st.spinner('AI æ­£åœ¨åˆ†æžäººåƒå¹¶è®¡ç®—ç§¯æœ¨åˆ†é…...'):
           p_weights = {
               'face': w_face, 'clothes': w_clothes,
               'bg_high': w_high, 'bg_normal': w_normal, 'bg_dark': w_dark
           }
           result_img, usage_stats = process_image(image, grid_size, p_weights)
           if result_img:
               with col2:
                   # ä½¿ç”¨ Nearest Neighbor æ”¾å¤§ï¼Œä¿æŒåƒç´ æ„Ÿ
                   st.image(result_img.resize((600, 600), resample=0),
                            caption="ä¹é«˜æ•ˆæžœé¢„è§ˆ", use_container_width=True)
               st.success("ç”ŸæˆæˆåŠŸï¼")
               # æ˜¾ç¤ºé›¶ä»¶æ¶ˆè€—ç»Ÿè®¡
               st.subheader("ðŸ“Š é›¶ä»¶æ¶ˆè€—ç»Ÿè®¡")
               cols = st.columns(3)
               for i, (name, count) in enumerate(usage_stats.items()):
                   original_stock = LEGO_31205_DATA[name][1]
                   cols[i % 3].metric(name, f"{count} é¢—", f"å‰©ä½™ {original_stock - count}")
           else:
               st.error("å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼ã€‚")
